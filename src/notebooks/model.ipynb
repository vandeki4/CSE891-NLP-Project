{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s_qNSzzyaCbD"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modified from https://www.tensorflow.org/tutorials/text/transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "jmjh290raIky"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in coampliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J0Qjg6vuaHNt"
   },
   "source": [
    "# Neural machine translation with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tnxXKDjq3jEL"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wfodePkj3jEa"
   },
   "source": [
    "## Download and prepare the dataset\n",
    "\n",
    "We'll use a language dataset provided by http://www.manythings.org/anki/. This dataset contains language translation pairs in the format:\n",
    "\n",
    "```\n",
    "May I borrow this book?\t¿Puedo tomar prestado este libro?\n",
    "```\n",
    "\n",
    "There are a variety of languages available, but we'll use the English-Spanish dataset. For convenience, we've hosted a copy of this dataset on Google Cloud, but you can also download your own copy. After downloading the dataset, here are the steps we'll take to prepare the data:\n",
    "\n",
    "1. Add a *start* and *end* token to each sentence.\n",
    "2. Clean the sentences by removing special characters.\n",
    "3. Create a word index and reverse word index (dictionaries mapping from word → id and id → word).\n",
    "4. Pad each sentence to a maximum length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kRVATYOgJs1b"
   },
   "outputs": [],
   "source": [
    "# Download the file\n",
    "# path_to_zip = tf.keras.utils.get_file(\n",
    "#     'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
    "#     extract=True)\n",
    "\n",
    "# path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rd0jw-eC3jEh"
   },
   "outputs": [],
   "source": [
    "# Converts the unicode file to ascii\n",
    "def unicode_to_ascii(s):\n",
    "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "      if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "  w = unicode_to_ascii(w.lower().strip())\n",
    "\n",
    "  # creating a space between a word and the punctuation following it\n",
    "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "  w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "\n",
    "  w = w.rstrip().strip()\n",
    "\n",
    "  # adding a start and an end token to the sentence\n",
    "  # so that the model know when to start and stop predicting.\n",
    "  w = '<start> ' + w + ' <end>'\n",
    "  return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "opI2GzOt479E"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> may i borrow this book ? <end>\n",
      "<start> ¿ puedo tomar prestado este libro ? <end>\n"
     ]
    }
   ],
   "source": [
    "en_sentence = u\"May I borrow this book?\"\n",
    "sp_sentence = u\"¿Puedo tomar prestado este libro?\"\n",
    "print(preprocess_sentence(en_sentence))\n",
    "print(preprocess_sentence(sp_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OHn4Dct23jEm"
   },
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from scripts.utility import pair_wise\n",
    "import itertools\n",
    "\n",
    "# 1. Remove the accents\n",
    "# 2. Clean the sentences\n",
    "# 3. Return word pairs in the format: [ENGLISH, SPANISH]\n",
    "def create_dataset(path, num_examples, max_tokens=80):\n",
    "  \n",
    "  pairs = pair_wise(f'{path}/europarl-v7.es-en.en', f'{path}/europarl-v7.es-en.es')\n",
    "  \n",
    "  word_pairs = ([preprocess_sentence(w) for w in pair] for pair in pairs)\n",
    "  limited_size_pairs = filter(lambda pair: all([sentence.count(' ') + 1 <= max_tokens for sentence in pair]), word_pairs)\n",
    "\n",
    "  return np.array(list(itertools.islice(limited_size_pairs, num_examples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cTbSbBz55QtF"
   },
   "outputs": [],
   "source": [
    "path_to_file = '../../dataset'\n",
    "num_examples = 30000\n",
    "\n",
    "train_and_test = create_dataset(path_to_file, num_examples)\n",
    "train_examples, val_examples = train_test_split(train_and_test, test_size=0.2)\n",
    "\n",
    "train_examples = tf.data.Dataset.from_tensor_slices(train_examples)\n",
    "val_examples = tf.data.Dataset.from_tensor_slices(val_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_en = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (en.numpy() for pt, en in train_examples), target_vocab_size=2**13)\n",
    "\n",
    "tokenizer_pt = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (pt.numpy() for pt, en in train_examples), target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized string is [7909, 2104, 7940, 7539, 39, 1942, 7922, 2021, 6615, 7926, 7871]\n",
      "The original string: Transformer is awesome.\n"
     ]
    }
   ],
   "source": [
    "sample_string = 'Transformer is awesome.'\n",
    "\n",
    "tokenized_string = tokenizer_en.encode(sample_string)\n",
    "print ('Tokenized string is {}'.format(tokenized_string))\n",
    "\n",
    "original_string = tokenizer_en.decode(tokenized_string)\n",
    "print ('The original string: {}'.format(original_string))\n",
    "\n",
    "assert original_string == sample_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7909 ----> T\n",
      "2104 ----> ran\n",
      "7940 ----> s\n",
      "7539 ----> forme\n",
      "39 ----> r \n",
      "1942 ----> is \n",
      "7922 ----> a\n",
      "2021 ----> we\n",
      "6615 ----> som\n",
      "7926 ----> e\n",
      "7871 ----> .\n"
     ]
    }
   ],
   "source": [
    "for ts in tokenized_string:\n",
    "    print ('{} ----> {}'.format(ts, tokenizer_en.decode([ts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 30000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(lang1, lang2):\n",
    "    lang1 = [tokenizer_pt.vocab_size] + tokenizer_pt.encode(\n",
    "        lang1.numpy()) + [tokenizer_pt.vocab_size+1]\n",
    "\n",
    "    lang2 = [tokenizer_en.vocab_size] + tokenizer_en.encode(\n",
    "        lang2.numpy()) + [tokenizer_en.vocab_size+1]\n",
    "  \n",
    "    return lang1, lang2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_encode(pten):\n",
    "    pt = pten[0]\n",
    "    en = pten[1]\n",
    "    result_pt, result_en = tf.py_function(encode, [pt, en], [tf.int64, tf.int64])\n",
    "    result_pt.set_shape([None])\n",
    "    result_en.set_shape([None])\n",
    "\n",
    "    return result_pt, result_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_max_length(x, y, max_length=MAX_LENGTH):\n",
    "  return tf.logical_and(tf.size(x) <= max_length,\n",
    "                        tf.size(y) <= max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preprocessed = (\n",
    "    train_examples\n",
    "    .map(tf_encode) \n",
    "    .filter(filter_max_length)\n",
    "    # cache the dataset to memory to get a speedup while reading from it.\n",
    "    .cache()\n",
    "    .shuffle(BUFFER_SIZE))\n",
    "\n",
    "val_preprocessed = (\n",
    "    val_examples\n",
    "    .map(tf_encode)\n",
    "    .filter(filter_max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = (train_preprocessed\n",
    "                 .padded_batch(BATCH_SIZE, padded_shapes=([None], [None]))\n",
    "                 .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "\n",
    "val_dataset = (val_preprocessed\n",
    "               .padded_batch(BATCH_SIZE,  padded_shapes=([None], [None])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(64, 71), dtype=int64, numpy=\n",
       " array([[8355, 8159,    4, ...,    0,    0,    0],\n",
       "        [8355, 8159,    4, ...,    3, 8161, 8356],\n",
       "        [8355, 8159,    4, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [8355, 8159,    4, ...,    0,    0,    0],\n",
       "        [8355, 8159,    4, ...,    0,    0,    0],\n",
       "        [8355, 8159,    4, ...,    0,    0,    0]], dtype=int64)>,\n",
       " <tf.Tensor: shape=(64, 79), dtype=int64, numpy=\n",
       " array([[8081, 7885,    5, ...,    0,    0,    0],\n",
       "        [8081, 7885,    5, ...,    0,    0,    0],\n",
       "        [8081, 7885,    5, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [8081, 7885,    5, ...,    0,    0,    0],\n",
       "        [8081, 7885,    5, ...,    0,    0,    0],\n",
       "        [8081, 7885,    5, ...,    0,    0,    0]], dtype=int64)>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_batch, en_batch = next(iter(val_dataset))\n",
    "pt_batch, en_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "  return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "  \n",
    "  # apply sin to even indices in the array; 2i\n",
    "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "  \n",
    "  # apply cos to odd indices in the array; 2i+1\n",
    "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "  pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    \n",
    "  return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 512)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos_encoding = positional_encoding(50, 512)\n",
    "print (pos_encoding.shape)\n",
    "\n",
    "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "  \n",
    "  # add extra dimensions to add the padding\n",
    "  # to the attention logits.\n",
    "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1, 1, 5), dtype=float32, numpy=\n",
       "array([[[[0., 0., 1., 1., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n",
    "create_padding_mask(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "  return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0., 1., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.uniform((1, 3))\n",
    "temp = create_look_ahead_mask(x.shape[1])\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "  \"\"\"Calculate the attention weights.\n",
    "  q, k, v must have matching leading dimensions.\n",
    "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "  The mask has different shapes depending on its type(padding or look ahead) \n",
    "  but it must be broadcastable for addition.\n",
    "  \n",
    "  Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable \n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "    \n",
    "  Returns:\n",
    "    output, attention_weights\n",
    "  \"\"\"\n",
    "\n",
    "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "  \n",
    "  # scale matmul_qk\n",
    "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "  # add the mask to the scaled tensor.\n",
    "  if mask is not None:\n",
    "    scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "  # add up to 1.\n",
    "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "  return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_out(q, k, v):\n",
    "  temp_out, temp_attn = scaled_dot_product_attention(\n",
    "      q, k, v, None)\n",
    "  print ('Attention weights are:')\n",
    "  print (temp_attn)\n",
    "  print ('Output is:')\n",
    "  print (temp_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "temp_k = tf.constant([[10,0,0],\n",
    "                      [0,10,0],\n",
    "                      [0,0,10],\n",
    "                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
    "\n",
    "temp_v = tf.constant([[   1,0],\n",
    "                      [  10,0],\n",
    "                      [ 100,5],\n",
    "                      [1000,6]], dtype=tf.float32)  # (4, 2)\n",
    "\n",
    "# This `query` aligns with the second `key`,\n",
    "# so the second `value` is returned.\n",
    "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# This query aligns with a repeated key (third and fourth), \n",
    "# so all associated values get averaged.\n",
    "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0.5 0.5 0.  0. ]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[5.5 0. ]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# This query aligns equally with the first and second key, \n",
    "# so their values get averaged.\n",
    "temp_q = tf.constant([[10, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor(\n",
      "[[0.  0.  0.5 0.5]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor(\n",
      "[[550.    5.5]\n",
      " [ 10.    0. ]\n",
      " [  5.5   0. ]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads):\n",
    "    super(MultiHeadAttention, self).__init__()\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "    \n",
    "    assert d_model % self.num_heads == 0\n",
    "    \n",
    "    self.depth = d_model // self.num_heads\n",
    "    \n",
    "    self.wq = tf.keras.layers.Dense(d_model)\n",
    "    self.wk = tf.keras.layers.Dense(d_model)\n",
    "    self.wv = tf.keras.layers.Dense(d_model)\n",
    "    \n",
    "    self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "  def split_heads(self, x, batch_size):\n",
    "    \"\"\"Split the last dimension into (num_heads, depth).\n",
    "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "    \"\"\"\n",
    "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "  def call(self, v, k, q, mask):\n",
    "    batch_size = tf.shape(q)[0]\n",
    "    \n",
    "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "    \n",
    "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "    \n",
    "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "        q, k, v, mask)\n",
    "    \n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "    concat_attention = tf.reshape(scaled_attention, \n",
    "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 60, 512]), TensorShape([1, 8, 60, 60]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
    "y = tf.random.uniform((1, 60, 512))  # (batch_size, encoder_sequence, d_model)\n",
    "out, attn = temp_mha(y, k=y, q=y, mask=None)\n",
    "out.shape, attn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "  return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "  ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_ffn = point_wise_feed_forward_network(512, 2048)\n",
    "sample_ffn(tf.random.uniform((64, 50, 512))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(EncoderLayer, self).__init__()\n",
    "\n",
    "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "    attn_output = self.dropout1(attn_output, training=training)\n",
    "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "    \n",
    "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "    ffn_output = self.dropout2(ffn_output, training=training)\n",
    "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "    \n",
    "    return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 43, 512])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_encoder_layer_output = sample_encoder_layer(\n",
    "    tf.random.uniform((64, 43, 512)), False, None)\n",
    "\n",
    "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(DecoderLayer, self).__init__()\n",
    "\n",
    "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    " \n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    \n",
    "  def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn1 = self.dropout1(attn1, training=training)\n",
    "    out1 = self.layernorm1(attn1 + x)\n",
    "    \n",
    "    attn2, attn_weights_block2 = self.mha2(\n",
    "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn2 = self.dropout2(attn2, training=training)\n",
    "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "    \n",
    "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "    ffn_output = self.dropout3(ffn_output, training=training)\n",
    "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "    \n",
    "    return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder_layer = DecoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
    "    tf.random.uniform((64, 50, 512)), sample_encoder_layer_output, \n",
    "    False, None, None)\n",
    "\n",
    "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super(Encoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "    \n",
    "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
    "                                            self.d_model)\n",
    "    \n",
    "    \n",
    "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "  \n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    \n",
    "    # adding embedding and position encoding.\n",
    "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "    x = self.dropout(x, training=training)\n",
    "    \n",
    "    for i in range(self.num_layers):\n",
    "      x = self.enc_layers[i](x, training, mask)\n",
    "    \n",
    "    return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 62, 512)\n"
     ]
    }
   ],
   "source": [
    "sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8, \n",
    "                         dff=2048, input_vocab_size=8500,\n",
    "                         maximum_position_encoding=10000)\n",
    "temp_input = tf.random.uniform((64, 62), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "sample_encoder_output = sample_encoder(temp_input, training=False, mask=None)\n",
    "\n",
    "print (sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "    \n",
    "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "    \n",
    "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "  def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    attention_weights = {}\n",
    "    \n",
    "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "    \n",
    "    x = self.dropout(x, training=training)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                             look_ahead_mask, padding_mask)\n",
    "      \n",
    "      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "    \n",
    "    # x.shape == (batch_size, target_seq_len, d_model)\n",
    "    return x, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 26, 512]), TensorShape([64, 8, 26, 62]))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8, \n",
    "                         dff=2048, target_vocab_size=8000,\n",
    "                         maximum_position_encoding=5000)\n",
    "temp_input = tf.random.uniform((64, 26), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "output, attn = sample_decoder(temp_input, \n",
    "                              enc_output=sample_encoder_output, \n",
    "                              training=False,\n",
    "                              look_ahead_mask=None, \n",
    "                              padding_mask=None)\n",
    "\n",
    "output.shape, attn['decoder_layer2_block2'].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
    "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "    super(Transformer, self).__init__()\n",
    "\n",
    "    self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
    "                           input_vocab_size, pe_input, rate)\n",
    "\n",
    "    self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
    "                           target_vocab_size, pe_target, rate)\n",
    "\n",
    "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "  def call(self, inp, tar, training, enc_padding_mask, \n",
    "           look_ahead_mask, dec_padding_mask):\n",
    "\n",
    "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "    \n",
    "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "    dec_output, attention_weights = self.decoder(\n",
    "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "    \n",
    "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "    \n",
    "    return final_output, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 36, 8000])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_transformer = Transformer(\n",
    "    num_layers=2, d_model=512, num_heads=8, dff=2048, \n",
    "    input_vocab_size=8500, target_vocab_size=8000, \n",
    "    pe_input=10000, pe_target=6000)\n",
    "\n",
    "temp_input = tf.random.uniform((64, 38), dtype=tf.int64, minval=0, maxval=200)\n",
    "temp_target = tf.random.uniform((64, 36), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "fn_out, _ = sample_transformer(temp_input, temp_target, training=False, \n",
    "                               enc_padding_mask=None, \n",
    "                               look_ahead_mask=None,\n",
    "                               dec_padding_mask=None)\n",
    "\n",
    "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = tokenizer_pt.vocab_size + 2\n",
    "target_vocab_size = tokenizer_en.vocab_size + 2\n",
    "dropout_rate = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "    \n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "    \n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "    \n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
    "\n",
    "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "  \n",
    "  return tf.reduce_mean(loss_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='train_accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size, \n",
    "                          pe_input=input_vocab_size, \n",
    "                          pe_target=target_vocab_size,\n",
    "                          rate=dropout_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "  # Encoder padding mask\n",
    "  enc_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "  # Used in the 2nd attention block in the decoder.\n",
    "  # This padding mask is used to mask the encoder outputs.\n",
    "  dec_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "  # Used in the 1st attention block in the decoder.\n",
    "  # It is used to pad and mask future tokens in the input received by \n",
    "  # the decoder.\n",
    "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "  dec_target_padding_mask = create_padding_mask(tar)\n",
    "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "  \n",
    "  return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoints/train\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "  print ('Latest checkpoint restored!!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
    "# execution. The function specializes to the precise shape of the argument\n",
    "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
    "# batch sizes (the last batch is smaller), use input_signature to specify\n",
    "# more generic shapes.\n",
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "]\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "  tar_inp = tar[:, :-1]\n",
    "  tar_real = tar[:, 1:]\n",
    "  \n",
    "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "  \n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions, _ = transformer(inp, tar_inp, \n",
    "                                 True, \n",
    "                                 enc_padding_mask, \n",
    "                                 combined_mask, \n",
    "                                 dec_padding_mask)\n",
    "    loss = loss_function(tar_real, predictions)\n",
    "\n",
    "  gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "  \n",
    "  train_loss(loss)\n",
    "  train_accuracy(tar_real, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 4.7252 Accuracy 0.0000\n",
      "Epoch 1 Batch 50 Loss 4.3111 Accuracy 0.0021\n",
      "Epoch 1 Batch 100 Loss 4.2616 Accuracy 0.0078\n",
      "Epoch 1 Batch 150 Loss 4.1971 Accuracy 0.0144\n",
      "Epoch 1 Batch 200 Loss 4.1411 Accuracy 0.0242\n",
      "Epoch 1 Batch 250 Loss 4.0554 Accuracy 0.0351\n",
      "Epoch 1 Batch 300 Loss 3.9607 Accuracy 0.0456\n",
      "Epoch 1 Batch 350 Loss 3.8587 Accuracy 0.0534\n",
      "Epoch 1 Loss 3.8313 Accuracy 0.0551\n",
      "Time taken for 1 epoch: 81.2401065826416 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 3.2848 Accuracy 0.1034\n",
      "Epoch 2 Batch 50 Loss 3.0643 Accuracy 0.1025\n",
      "Epoch 2 Batch 100 Loss 2.9635 Accuracy 0.1109\n",
      "Epoch 2 Batch 150 Loss 2.8895 Accuracy 0.1172\n",
      "Epoch 2 Batch 200 Loss 2.8084 Accuracy 0.1213\n",
      "Epoch 2 Batch 250 Loss 2.7381 Accuracy 0.1249\n",
      "Epoch 2 Batch 300 Loss 2.6789 Accuracy 0.1275\n",
      "Epoch 2 Batch 350 Loss 2.6302 Accuracy 0.1299\n",
      "Epoch 2 Loss 2.6189 Accuracy 0.1305\n",
      "Time taken for 1 epoch: 40.918529748916626 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 2.0883 Accuracy 0.1433\n",
      "Epoch 3 Batch 50 Loss 2.2436 Accuracy 0.1482\n",
      "Epoch 3 Batch 100 Loss 2.2184 Accuracy 0.1499\n",
      "Epoch 3 Batch 150 Loss 2.2191 Accuracy 0.1520\n",
      "Epoch 3 Batch 200 Loss 2.2117 Accuracy 0.1534\n",
      "Epoch 3 Batch 250 Loss 2.1950 Accuracy 0.1543\n",
      "Epoch 3 Batch 300 Loss 2.1871 Accuracy 0.1552\n",
      "Epoch 3 Batch 350 Loss 2.1740 Accuracy 0.1559\n",
      "Epoch 3 Loss 2.1705 Accuracy 0.1560\n",
      "Time taken for 1 epoch: 39.77053165435791 secs\n",
      "\n",
      "Epoch 4 Batch 0 Loss 2.1331 Accuracy 0.1645\n",
      "Epoch 4 Batch 50 Loss 2.0387 Accuracy 0.1627\n",
      "Epoch 4 Batch 100 Loss 2.0268 Accuracy 0.1621\n",
      "Epoch 4 Batch 150 Loss 2.0336 Accuracy 0.1626\n",
      "Epoch 4 Batch 200 Loss 2.0274 Accuracy 0.1628\n",
      "Epoch 4 Batch 250 Loss 2.0232 Accuracy 0.1636\n",
      "Epoch 4 Batch 300 Loss 2.0187 Accuracy 0.1642\n",
      "Epoch 4 Batch 350 Loss 2.0110 Accuracy 0.1647\n",
      "Epoch 4 Loss 2.0070 Accuracy 0.1648\n",
      "Time taken for 1 epoch: 43.03018069267273 secs\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.8703 Accuracy 0.1661\n",
      "Epoch 5 Batch 50 Loss 1.8960 Accuracy 0.1702\n",
      "Epoch 5 Batch 100 Loss 1.9241 Accuracy 0.1728\n",
      "Epoch 5 Batch 150 Loss 1.9159 Accuracy 0.1726\n",
      "Epoch 5 Batch 200 Loss 1.9092 Accuracy 0.1729\n",
      "Epoch 5 Batch 250 Loss 1.9039 Accuracy 0.1735\n",
      "Epoch 5 Batch 300 Loss 1.9044 Accuracy 0.1740\n",
      "Epoch 5 Batch 350 Loss 1.8972 Accuracy 0.1741\n",
      "Saving checkpoint for epoch 5 at ./checkpoints/train\\ckpt-1\n",
      "Epoch 5 Loss 1.8983 Accuracy 0.1742\n",
      "Time taken for 1 epoch: 40.16054916381836 secs\n",
      "\n",
      "Epoch 6 Batch 0 Loss 1.7750 Accuracy 0.1809\n",
      "Epoch 6 Batch 50 Loss 1.8294 Accuracy 0.1811\n",
      "Epoch 6 Batch 100 Loss 1.8126 Accuracy 0.1807\n",
      "Epoch 6 Batch 150 Loss 1.8181 Accuracy 0.1813\n",
      "Epoch 6 Batch 200 Loss 1.8092 Accuracy 0.1812\n",
      "Epoch 6 Batch 250 Loss 1.8125 Accuracy 0.1818\n",
      "Epoch 6 Batch 300 Loss 1.8078 Accuracy 0.1819\n",
      "Epoch 6 Batch 350 Loss 1.8024 Accuracy 0.1819\n",
      "Epoch 6 Loss 1.8008 Accuracy 0.1820\n",
      "Time taken for 1 epoch: 41.57234978675842 secs\n",
      "\n",
      "Epoch 7 Batch 0 Loss 1.8574 Accuracy 0.1962\n",
      "Epoch 7 Batch 50 Loss 1.7174 Accuracy 0.1889\n",
      "Epoch 7 Batch 100 Loss 1.7127 Accuracy 0.1889\n",
      "Epoch 7 Batch 150 Loss 1.7086 Accuracy 0.1881\n",
      "Epoch 7 Batch 200 Loss 1.7077 Accuracy 0.1882\n",
      "Epoch 7 Batch 250 Loss 1.7118 Accuracy 0.1887\n",
      "Epoch 7 Batch 300 Loss 1.7142 Accuracy 0.1892\n",
      "Epoch 7 Batch 350 Loss 1.7098 Accuracy 0.1893\n",
      "Epoch 7 Loss 1.7094 Accuracy 0.1894\n",
      "Time taken for 1 epoch: 40.72912049293518 secs\n",
      "\n",
      "Epoch 8 Batch 0 Loss 1.5761 Accuracy 0.1851\n",
      "Epoch 8 Batch 50 Loss 1.6304 Accuracy 0.1972\n",
      "Epoch 8 Batch 100 Loss 1.6318 Accuracy 0.1976\n",
      "Epoch 8 Batch 150 Loss 1.6201 Accuracy 0.1963\n",
      "Epoch 8 Batch 200 Loss 1.6219 Accuracy 0.1967\n",
      "Epoch 8 Batch 250 Loss 1.6257 Accuracy 0.1969\n",
      "Epoch 8 Batch 300 Loss 1.6242 Accuracy 0.1973\n",
      "Epoch 8 Batch 350 Loss 1.6227 Accuracy 0.1977\n",
      "Epoch 8 Loss 1.6228 Accuracy 0.1980\n",
      "Time taken for 1 epoch: 40.06068968772888 secs\n",
      "\n",
      "Epoch 9 Batch 0 Loss 1.7166 Accuracy 0.2075\n",
      "Epoch 9 Batch 50 Loss 1.5193 Accuracy 0.2070\n",
      "Epoch 9 Batch 100 Loss 1.5241 Accuracy 0.2074\n",
      "Epoch 9 Batch 150 Loss 1.5284 Accuracy 0.2062\n",
      "Epoch 9 Batch 200 Loss 1.5343 Accuracy 0.2071\n",
      "Epoch 9 Batch 250 Loss 1.5275 Accuracy 0.2065\n",
      "Epoch 9 Batch 300 Loss 1.5232 Accuracy 0.2063\n",
      "Epoch 9 Batch 350 Loss 1.5266 Accuracy 0.2068\n",
      "Epoch 9 Loss 1.5277 Accuracy 0.2070\n",
      "Time taken for 1 epoch: 38.71099495887756 secs\n",
      "\n",
      "Epoch 10 Batch 0 Loss 1.6591 Accuracy 0.2557\n",
      "Epoch 10 Batch 50 Loss 1.4281 Accuracy 0.2192\n",
      "Epoch 10 Batch 100 Loss 1.4296 Accuracy 0.2187\n",
      "Epoch 10 Batch 150 Loss 1.4286 Accuracy 0.2180\n",
      "Epoch 10 Batch 200 Loss 1.4339 Accuracy 0.2178\n",
      "Epoch 10 Batch 250 Loss 1.4348 Accuracy 0.2177\n",
      "Epoch 10 Batch 300 Loss 1.4342 Accuracy 0.2178\n",
      "Epoch 10 Batch 350 Loss 1.4366 Accuracy 0.2178\n",
      "Saving checkpoint for epoch 10 at ./checkpoints/train\\ckpt-2\n",
      "Epoch 10 Loss 1.4363 Accuracy 0.2177\n",
      "Time taken for 1 epoch: 40.269495248794556 secs\n",
      "\n",
      "Epoch 11 Batch 0 Loss 1.0067 Accuracy 0.2056\n",
      "Epoch 11 Batch 50 Loss 1.3117 Accuracy 0.2281\n",
      "Epoch 11 Batch 100 Loss 1.3265 Accuracy 0.2297\n",
      "Epoch 11 Batch 150 Loss 1.3351 Accuracy 0.2299\n",
      "Epoch 11 Batch 200 Loss 1.3359 Accuracy 0.2298\n",
      "Epoch 11 Batch 250 Loss 1.3409 Accuracy 0.2298\n",
      "Epoch 11 Batch 300 Loss 1.3425 Accuracy 0.2293\n",
      "Epoch 11 Batch 350 Loss 1.3435 Accuracy 0.2293\n",
      "Epoch 11 Loss 1.3439 Accuracy 0.2291\n",
      "Time taken for 1 epoch: 38.07376408576965 secs\n",
      "\n",
      "Epoch 12 Batch 0 Loss 1.1922 Accuracy 0.2234\n",
      "Epoch 12 Batch 50 Loss 1.2384 Accuracy 0.2449\n",
      "Epoch 12 Batch 100 Loss 1.2435 Accuracy 0.2436\n",
      "Epoch 12 Batch 150 Loss 1.2446 Accuracy 0.2421\n",
      "Epoch 12 Batch 200 Loss 1.2445 Accuracy 0.2409\n",
      "Epoch 12 Batch 250 Loss 1.2495 Accuracy 0.2411\n",
      "Epoch 12 Batch 300 Loss 1.2522 Accuracy 0.2408\n",
      "Epoch 12 Batch 350 Loss 1.2532 Accuracy 0.2408\n",
      "Epoch 12 Loss 1.2539 Accuracy 0.2409\n",
      "Time taken for 1 epoch: 38.79962491989136 secs\n",
      "\n",
      "Epoch 13 Batch 0 Loss 1.0660 Accuracy 0.2529\n",
      "Epoch 13 Batch 50 Loss 1.1215 Accuracy 0.2560\n",
      "Epoch 13 Batch 100 Loss 1.1285 Accuracy 0.2549\n",
      "Epoch 13 Batch 150 Loss 1.1334 Accuracy 0.2527\n",
      "Epoch 13 Batch 200 Loss 1.1467 Accuracy 0.2521\n",
      "Epoch 13 Batch 250 Loss 1.1513 Accuracy 0.2516\n",
      "Epoch 13 Batch 300 Loss 1.1560 Accuracy 0.2512\n",
      "Epoch 13 Batch 350 Loss 1.1623 Accuracy 0.2512\n",
      "Epoch 13 Loss 1.1631 Accuracy 0.2513\n",
      "Time taken for 1 epoch: 41.160151958465576 secs\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.9327 Accuracy 0.2476\n",
      "Epoch 14 Batch 50 Loss 1.0608 Accuracy 0.2713\n",
      "Epoch 14 Batch 100 Loss 1.0545 Accuracy 0.2669\n",
      "Epoch 14 Batch 150 Loss 1.0619 Accuracy 0.2643\n",
      "Epoch 14 Batch 200 Loss 1.0700 Accuracy 0.2637\n",
      "Epoch 14 Batch 250 Loss 1.0799 Accuracy 0.2634\n",
      "Epoch 14 Batch 300 Loss 1.0841 Accuracy 0.2629\n",
      "Epoch 14 Batch 350 Loss 1.0907 Accuracy 0.2623\n",
      "Epoch 14 Loss 1.0931 Accuracy 0.2624\n",
      "Time taken for 1 epoch: 41.342668294906616 secs\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.8808 Accuracy 0.2697\n",
      "Epoch 15 Batch 50 Loss 0.9725 Accuracy 0.2720\n",
      "Epoch 15 Batch 100 Loss 0.9938 Accuracy 0.2741\n",
      "Epoch 15 Batch 150 Loss 0.9968 Accuracy 0.2724\n",
      "Epoch 15 Batch 200 Loss 1.0041 Accuracy 0.2715\n",
      "Epoch 15 Batch 250 Loss 1.0078 Accuracy 0.2710\n",
      "Epoch 15 Batch 300 Loss 1.0138 Accuracy 0.2702\n",
      "Epoch 15 Batch 350 Loss 1.0223 Accuracy 0.2697\n",
      "Saving checkpoint for epoch 15 at ./checkpoints/train\\ckpt-3\n",
      "Epoch 15 Loss 1.0246 Accuracy 0.2697\n",
      "Time taken for 1 epoch: 44.38903284072876 secs\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.7206 Accuracy 0.2464\n",
      "Epoch 16 Batch 50 Loss 0.9039 Accuracy 0.2822\n",
      "Epoch 16 Batch 100 Loss 0.9291 Accuracy 0.2842\n",
      "Epoch 16 Batch 150 Loss 0.9402 Accuracy 0.2820\n",
      "Epoch 16 Batch 200 Loss 0.9447 Accuracy 0.2799\n",
      "Epoch 16 Batch 250 Loss 0.9532 Accuracy 0.2796\n",
      "Epoch 16 Batch 300 Loss 0.9631 Accuracy 0.2791\n",
      "Epoch 16 Batch 350 Loss 0.9695 Accuracy 0.2784\n",
      "Epoch 16 Loss 0.9706 Accuracy 0.2783\n",
      "Time taken for 1 epoch: 40.400066614151 secs\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.7153 Accuracy 0.2515\n",
      "Epoch 17 Batch 50 Loss 0.8669 Accuracy 0.2922\n",
      "Epoch 17 Batch 100 Loss 0.8789 Accuracy 0.2909\n",
      "Epoch 17 Batch 150 Loss 0.8886 Accuracy 0.2898\n",
      "Epoch 17 Batch 200 Loss 0.8961 Accuracy 0.2883\n",
      "Epoch 17 Batch 250 Loss 0.9048 Accuracy 0.2869\n",
      "Epoch 17 Batch 300 Loss 0.9123 Accuracy 0.2862\n",
      "Epoch 17 Batch 350 Loss 0.9200 Accuracy 0.2853\n",
      "Epoch 17 Loss 0.9212 Accuracy 0.2851\n",
      "Time taken for 1 epoch: 41.99324679374695 secs\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.7960 Accuracy 0.3117\n",
      "Epoch 18 Batch 50 Loss 0.8261 Accuracy 0.3024\n",
      "Epoch 18 Batch 100 Loss 0.8385 Accuracy 0.3011\n",
      "Epoch 18 Batch 150 Loss 0.8462 Accuracy 0.2977\n",
      "Epoch 18 Batch 200 Loss 0.8561 Accuracy 0.2953\n",
      "Epoch 18 Batch 250 Loss 0.8621 Accuracy 0.2934\n",
      "Epoch 18 Batch 300 Loss 0.8701 Accuracy 0.2923\n",
      "Epoch 18 Batch 350 Loss 0.8776 Accuracy 0.2918\n",
      "Epoch 18 Loss 0.8791 Accuracy 0.2915\n",
      "Time taken for 1 epoch: 40.27717089653015 secs\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.6525 Accuracy 0.2636\n",
      "Epoch 19 Batch 50 Loss 0.7798 Accuracy 0.3080\n",
      "Epoch 19 Batch 100 Loss 0.7910 Accuracy 0.3049\n",
      "Epoch 19 Batch 150 Loss 0.8033 Accuracy 0.3025\n",
      "Epoch 19 Batch 200 Loss 0.8158 Accuracy 0.3009\n",
      "Epoch 19 Batch 250 Loss 0.8251 Accuracy 0.3000\n",
      "Epoch 19 Batch 300 Loss 0.8314 Accuracy 0.2986\n",
      "Epoch 19 Batch 350 Loss 0.8389 Accuracy 0.2978\n",
      "Epoch 19 Loss 0.8386 Accuracy 0.2971\n",
      "Time taken for 1 epoch: 42.74284601211548 secs\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.7920 Accuracy 0.3281\n",
      "Epoch 20 Batch 50 Loss 0.7456 Accuracy 0.3089\n",
      "Epoch 20 Batch 100 Loss 0.7601 Accuracy 0.3099\n",
      "Epoch 20 Batch 150 Loss 0.7750 Accuracy 0.3089\n",
      "Epoch 20 Batch 200 Loss 0.7827 Accuracy 0.3073\n",
      "Epoch 20 Batch 250 Loss 0.7945 Accuracy 0.3064\n",
      "Epoch 20 Batch 300 Loss 0.7991 Accuracy 0.3043\n",
      "Epoch 20 Batch 350 Loss 0.8045 Accuracy 0.3029\n",
      "Saving checkpoint for epoch 20 at ./checkpoints/train\\ckpt-4\n",
      "Epoch 20 Loss 0.8058 Accuracy 0.3024\n",
      "Time taken for 1 epoch: 43.66165041923523 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "  \n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "  \n",
    "  # inp -> portuguese, tar -> english\n",
    "  for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "    train_step(inp, tar)\n",
    "    \n",
    "    if batch % 50 == 0:\n",
    "      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
    "      \n",
    "  if (epoch + 1) % 5 == 0:\n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                         ckpt_save_path))\n",
    "    \n",
    "  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                train_loss.result(), \n",
    "                                                train_accuracy.result()))\n",
    "\n",
    "  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(inp_sentence):\n",
    "  start_token = [tokenizer_pt.vocab_size]\n",
    "  end_token = [tokenizer_pt.vocab_size + 1]\n",
    "  \n",
    "  # inp sentence is portuguese, hence adding the start and end token\n",
    "  inp_sentence = start_token + tokenizer_pt.encode(inp_sentence) + end_token\n",
    "  encoder_input = tf.expand_dims(inp_sentence, 0) # [batch_size, n]\n",
    "  \n",
    "  # as the target is english, the first word to the transformer should be the\n",
    "  # english start token.\n",
    "  decoder_input = [tokenizer_en.vocab_size]\n",
    "  output = tf.expand_dims(decoder_input, 0)\n",
    "    \n",
    "  for i in range(MAX_LENGTH):\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "        encoder_input, output)\n",
    "        \n",
    "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "    predictions, attention_weights = transformer(encoder_input, \n",
    "                                                 output,\n",
    "                                                 False,\n",
    "                                                 enc_padding_mask,\n",
    "                                                 combined_mask,\n",
    "                                                 dec_padding_mask)\n",
    "    \n",
    "    # select the last word from the seq_len dimension\n",
    "    predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "    \n",
    "    # return the result if the predicted_id is equal to the end token\n",
    "    if predicted_id == tokenizer_en.vocab_size+1:\n",
    "      return tf.squeeze(output, axis=0), attention_weights\n",
    "    \n",
    "    # concatentate the predicted_id to the output which is given to the decoder\n",
    "    # as its input.\n",
    "    output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output, axis=0), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_raw(encoder_input):\n",
    "  # as the target is english, the first word to the transformer should be the\n",
    "  # english start token.\n",
    "  decoder_input = [tokenizer_en.vocab_size]\n",
    "  output = tf.expand_dims(decoder_input, 0)\n",
    "\n",
    "  output = tf.constant(tokenizer_en.vocab_size, shape=(encoder_input.shape[0], 1))\n",
    "  \n",
    "    \n",
    "  for i in range(MAX_LENGTH):\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "        encoder_input, output)\n",
    "        \n",
    "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "    predictions, attention_weights = transformer(encoder_input, \n",
    "                                                 output,\n",
    "                                                 False,\n",
    "                                                 enc_padding_mask,\n",
    "                                                 combined_mask,\n",
    "                                                 dec_padding_mask)\n",
    "    \n",
    "    # select the last word from the seq_len dimension\n",
    "    predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "    \n",
    "#     # return the result if the predicted_id is equal to the end token\n",
    "#     if predicted_id == tokenizer_en.vocab_size+1:\n",
    "#       return tf.squeeze(output, axis=0), attention_weights\n",
    "    \n",
    "    # concatentate the predicted_id to the output which is given to the decoder\n",
    "    # as its input.\n",
    "    output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "  return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "  result, attention_weights = evaluate(sentence)\n",
    "  \n",
    "  predicted_sentence = tokenizer_en.decode([i for i in result \n",
    "                                            if i < tokenizer_en.vocab_size])  \n",
    "\n",
    "  print('Input: {}'.format(sentence))\n",
    "  print('Predicted translation: {}'.format(predicted_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(28,), dtype=int32, numpy=\n",
       "array([8081, 7885,    5,    6,   20, 3585,   17,   20, 5449, 7857,    7,\n",
       "         15, 2224,  415,   11,   21,  599,    1,  249,   35, 5248, 7857,\n",
       "          9,   21,  725,    8,    4, 7887])>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result, attention_weights = evaluate('This is a sentence to be translated at a later time.')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47dceb9372c845aaa67ae5bcf50ca2d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BLEU (val): 0.27337851137718927\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "count = 0\n",
    "total = 0\n",
    "\n",
    "for eng, sp in tqdm(val_dataset):\n",
    "    predicted, attention_weights = evaluate_raw(eng)\n",
    "    \n",
    "    for predicted_sentence, ground_truth in zip(predicted, sp):\n",
    "        try:\n",
    "            py_sentence = predicted_sentence.numpy().tolist()\n",
    "            stoppoint = py_sentence.index(tokenizer_en.vocab_size+1)\n",
    "            trimmed_prediction = py_sentence[:stoppoint+1]\n",
    "\n",
    "            py_sentence = ground_truth.numpy().tolist()\n",
    "            stoppoint = py_sentence.index(tokenizer_en.vocab_size+1)\n",
    "            trimmed_truth = py_sentence[:stoppoint+1]\n",
    "\n",
    "            score = sentence_bleu([trimmed_truth], trimmed_prediction)\n",
    "\n",
    "            count += 1\n",
    "            total += score\n",
    "        except Exception: pass\n",
    "print(f\"BLEU (val): {total / count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f3b821a5d33494394e788f74b622f8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BLEU (val): 0.3464219288168457\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "total = 0\n",
    "\n",
    "for eng, sp in tqdm(train_dataset):\n",
    "    predicted, attention_weights = evaluate_raw(eng)\n",
    "    \n",
    "    for predicted_sentence, ground_truth in zip(predicted, sp):\n",
    "        try:\n",
    "            py_sentence = predicted_sentence.numpy().tolist()\n",
    "            stoppoint = py_sentence.index(tokenizer_en.vocab_size+1)\n",
    "            trimmed_prediction = py_sentence[:stoppoint+1]\n",
    "\n",
    "            py_sentence = ground_truth.numpy().tolist()\n",
    "            stoppoint = py_sentence.index(tokenizer_en.vocab_size+1)\n",
    "            trimmed_truth = py_sentence[:stoppoint+1]\n",
    "\n",
    "            score = sentence_bleu([trimmed_truth], trimmed_prediction)\n",
    "\n",
    "            count += 1\n",
    "            total += score\n",
    "        except Exception: pass\n",
    "print(f\"BLEU (train): {total / count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "nmt_with_attention.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
